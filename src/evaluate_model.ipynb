{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from resnet18 import *\n",
    "from char2img import *\n",
    "from letters import *\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"using Cuda\")\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_built():\n",
    "    print(\"using MPS\")\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    print(\"using CPU\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "experiment_name = \"robust\"\n",
    "#model = ResNet18(num_classes=ABC_SIZE + len(additional_symbols))\n",
    "model = ResNet18()\n",
    "model.load_state_dict(torch.load(f'models/resnet18_{experiment_name}.pth'))\n",
    "model = model.to(device)\n",
    "\n",
    "# Compute the mean and std of the dataset\n",
    "dataset = LettersDataset(f\"data/letters_{experiment_name}.csv\", device)\n",
    "mean = torch.mean(torch.stack([array.mean() for array, _ in dataset]))\n",
    "std = torch.std(torch.stack([array.std() for array, _ in dataset]))\n",
    "print(f\"{mean = }\")\n",
    "print(f\"{std = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inference\n",
    "def inference(text, model):\n",
    "    array = generate_chars_image(text)\n",
    "    show_img(array)\n",
    "    tensor = torch.tensor(array).unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "    tensor = (tensor - mean) / std\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Inference\n",
    "        logits = model(tensor)\n",
    "\n",
    "        # Extract only the logits corresponding to letters\n",
    "        letter_logits = logits[:, :ABC_SIZE]\n",
    "        \n",
    "        # Calculate softmax probabilities only on letter logits\n",
    "        probas = F.softmax(letter_logits, dim=1)\n",
    "\n",
    "        # Print the predicted label\n",
    "        predicted_label = torch.argmax(probas).item()\n",
    "        predicted_prob = probas[0][predicted_label]\n",
    "        print(f\"Label: {chr(predicted_label + ord('A'))}, Probability: {predicted_prob:.4f}\")\n",
    "\n",
    "        # Print other labels with relatively high probability\n",
    "        for i in range(len(probas[0])):\n",
    "            if probas[0][i] > (predicted_prob * 0.5) and i != predicted_label:\n",
    "                print(f\"Label: {chr(i + ord('A'))}, Probability: {probas[0][i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(text_list, labels_list, model):\n",
    "    dataset_size = len(text_list)\n",
    "    num_correct = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for text, label in zip(text_list, labels_list):\n",
    "            array = generate_chars_image(text)\n",
    "\n",
    "            # Normalize\n",
    "            tensor = torch.tensor(array).unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "            tensor = (tensor - mean) / std\n",
    "\n",
    "            # Inference\n",
    "            logits = model(tensor)\n",
    "\n",
    "            # Extract only the logits corresponding to letters\n",
    "            letter_logits = logits[:, :ABC_SIZE]\n",
    "            \n",
    "            # Calculate softmax probabilities only on letter logits\n",
    "            probas = F.softmax(letter_logits, dim=1)\n",
    "            \n",
    "            # Get the predicted letter class\n",
    "            predicted_class = chr(torch.argmax(probas).item() + ord('A'))\n",
    "            \n",
    "            if predicted_class == label:\n",
    "                num_correct += 1\n",
    "\n",
    "    return round((num_correct / dataset_size) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate upper case letters are predicted correctly\n",
    "accuracy = evaluate(upper_case_alphabet, upper_case_alphabet, model)\n",
    "print(f\"Upper-case accuracy: {accuracy}\")\n",
    "\n",
    "# evaluate upper case letters are predicted correctly\n",
    "accuracy = evaluate(lower_case_alphabet, upper_case_alphabet, model)\n",
    "print(f\"Lower-case accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate leet speak substitutions are predicted correctly\n",
    "\n",
    "total_accuracy = 0\n",
    "for letter in upper_case_alphabet:\n",
    "    n_subs = len(leet_speak_alphabet[letter])\n",
    "    labels = [letter] * n_subs\n",
    "    accuracy = evaluate(leet_speak_alphabet[letter], labels, model)\n",
    "    print(f\"Letter {letter} accuracy: {accuracy}\")\n",
    "    total_accuracy += accuracy\n",
    "print(f\"Total accuracy: {total_accuracy / len(upper_case_alphabet)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for letter in lower_case_alphabet:\n",
    "    inference(letter, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference('|-|', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for letter in upper_case_alphabet:\n",
    "    for sub in leet_speak_alphabet[letter]:\n",
    "        inference(sub, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
